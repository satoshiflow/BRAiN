# ğŸ§ª BRAiN Credit System â€” Live Test Playbook

**Scope:** Event Sourcing Foundation (Phasen 7â€“10) â€” StabilitÃ¤t & Governance
**Testtyp:** Live System Validation (File-based, Single-Instance)
**Branch:** `claude/event-sourcing-foundation-GmJza`
**Verantwortlich:** Lead Engineer & Reliability Owner

---

## ğŸ“‹ Inhaltsverzeichnis

1. [Voraussetzungen](#voraussetzungen)
2. [Testumgebung Setup](#testumgebung-setup)
3. [Testparameter](#testparameter)
4. [Testszenarien](#testszenarien)
5. [Hard Gates](#hard-gates)
6. [AusfÃ¼hrung](#ausfÃ¼hrung)
7. [Erwartete Ergebnisse](#erwartete-ergebnisse)
8. [Failure Symptome](#failure-symptome)
9. [Cleanup & Wiederholung](#cleanup--wiederholung)

---

## 1ï¸âƒ£ Voraussetzungen

### Infrastruktur

| Komponente | Version | Status | Erforderlich? |
|------------|---------|--------|---------------|
| Docker | â‰¥ 20.10 | âœ… Installiert | âœ… JA |
| Docker Compose | â‰¥ 2.0 | âœ… Installiert | âœ… JA |
| Python | â‰¥ 3.11 | âœ… Container | âœ… JA (im Backend) |
| PostgreSQL | 16 | âš ï¸ Dormant | âŒ NEIN |
| Redis | 7 | âš ï¸ Dormant | âŒ NEIN |

**Wichtig:** Postgres und Redis sind im Compose definiert, werden aber **logisch nicht genutzt**.

### Repository Status

```bash
# Branch checken
git branch --show-current
# â†’ claude/event-sourcing-foundation-GmJza

# Letzter Commit
git log -1 --oneline
# â†’ 3e25513 feat: Event Sourcing Next Steps - Integration & Extensions
```

### Verzeichnisstruktur

```bash
backend/
â”œâ”€â”€ app/modules/credits/
â”‚   â”œâ”€â”€ event_sourcing/          # Core Event Sourcing
â”‚   â”‚   â”œâ”€â”€ events.py
â”‚   â”‚   â”œâ”€â”€ event_journal.py     # File-based JSONL
â”‚   â”‚   â”œâ”€â”€ event_bus.py
â”‚   â”‚   â”œâ”€â”€ projections.py       # In-Memory
â”‚   â”‚   â””â”€â”€ replay.py
â”‚   â”œâ”€â”€ integration_demo.py      # CreditSystemDemo
â”‚   â”œâ”€â”€ service.py               # Service Layer
â”‚   â”œâ”€â”€ router.py                # REST API
â”‚   â”œâ”€â”€ analytics.py             # Advanced Analytics
â”‚   â”œâ”€â”€ mission_integration.py   # Mission Hooks
â”‚   â””â”€â”€ resource_pools.py        # Shared Pools
â””â”€â”€ tests/
    â”œâ”€â”€ run_live_credit_tests.py     # â† Test Harness (zu erstellen)
    â”œâ”€â”€ live_invariants.py           # â† Invarianten-Checker (zu erstellen)
    â””â”€â”€ live_credit_system_playbook.md  # â† Dieses Dokument
```

---

## 2ï¸âƒ£ Testumgebung Setup

### Schritt 1: Services starten

```bash
# Ins Projekt-Root wechseln
cd /home/user/BRAiN

# NUR Backend starten (ausreichend!)
docker compose up -d backend

# Verifizieren
docker compose ps
# â†’ backend: Up (8000->8000)
```

**Warum nur Backend?**
- Event Sourcing ist **file-based** (JSONL)
- Projections sind **In-Memory**
- Keine DB-Dependencies

### Schritt 2: Healthcheck

```bash
# API erreichbar?
curl http://localhost:8000/api/health
# â†’ {"status": "healthy"}

# Credits Module erreichbar?
curl http://localhost:8000/api/credits/health
# â†’ {"status": "healthy", "event_sourcing": true}
```

### Schritt 3: Event Journal initialisieren

```bash
# Automatisch beim ersten Event angelegt
# Pfad: storage/events/credits.jsonl

# Manuell anlegen (optional)
docker compose exec backend mkdir -p /app/storage/events
```

### Schritt 4: Test-AbhÃ¤ngigkeiten (im Container)

```bash
# Im Backend-Container
docker compose exec backend pip list | grep -E "pytest|httpx|loguru"
# â†’ Sollte bereits installiert sein
```

---

## 3ï¸âƒ£ Testparameter

### Konfigurierbare Parameter

| Parameter | Wert (Default) | Beschreibung |
|-----------|----------------|--------------|
| `CONCURRENCY` | 50, 100, 300 | Parallele Anfragen |
| `TEST_DURATION` | 30 Minuten | Dauerlauf-Dauer |
| `RETRY_INJECTION` | True | Duplicate Requests |
| `SEED` | 42 | Deterministischer Seed |
| `KARMA_ENABLED` | False | LLM-VerfÃ¼gbarkeit simulieren |
| `ML_ANOMALY_INJECTION` | True | Anomalie-Injection |

### Umgebungsvariablen (optional)

```bash
# Ãœberschreiben via ENV
export LIVE_TEST_CONCURRENCY=100
export LIVE_TEST_DURATION=1800  # 30 Minuten in Sekunden
export LIVE_TEST_SEED=42
```

---

## 4ï¸âƒ£ Testszenarien

### Szenario 1: Credit Storm / Reuse Cascade

**Ziel:** PrÃ¼fen, ob massive parallele Credit-Konsumierung Balances korrekt hÃ¤lt

**Setup:**
- 10 Agents mit je 1000 Credits
- 50 parallele Threads
- Jeder Thread: 20 Consume-Operationen (zufÃ¤llige BetrÃ¤ge)

**Erwartung:**
- âœ… Alle Balances >= 0
- âœ… Keine Idempotency-Violations
- âœ… `balance == sum(event_deltas)`

**Failure-Symptome:**
- âŒ Negative Balances
- âŒ NaN / Inf in Balances
- âŒ Drift zwischen Events und Projections

---

### Szenario 2: Synergy Anti-Gaming Loop

**Ziel:** PrÃ¼fen, ob Synergie-Rewards begrenzt sind (Anti-Gaming)

**Setup:**
- 5 Agents in Team "Alpha"
- 100 Synergie-Events (simuliert)
- Reward-Deckel: 500 Credits

**Erwartung:**
- âœ… Kein Agent > 500 Credits aus Synergie
- âœ… Audit-Log zeigt "reward_capped" Events

**Failure-Symptome:**
- âŒ Unbegrenzte Rewards
- âŒ Missing Audit Events

---

### Szenario 3: Approval Race / Concurrency

**Ziel:** PrÃ¼fen, ob parallele Approval-Requests serialisiert werden (OCC)

**Setup:**
- 1 Agent wartet auf Approval fÃ¼r 500 Credits
- 10 parallele Approve/Deny Requests

**Erwartung:**
- âœ… Nur 1 Approval wirksam
- âœ… Restliche Requests: "already_decided" Error
- âœ… Audit-Log vollstÃ¤ndig

**Failure-Symptome:**
- âŒ Mehrfache Approvals
- âŒ Inkonsistenter Approval-State
- âŒ Fehlende Audit-EintrÃ¤ge

---

### Szenario 4: KARMA Blackout

**Ziel:** PrÃ¼fen, ob System ohne KARMA-LLM stabil bleibt

**Setup:**
- KARMA-Service simuliert "unavailable"
- 50 Credit-Operationen
- Fallback-Modus aktiv

**Erwartung:**
- âœ… System lÃ¤uft weiter (degraded mode)
- âœ… Keine Crashes
- âœ… Fallback-Logik greift (z. B. Default CI = 0.5)

**Failure-Symptome:**
- âŒ System-Crash bei KARMA-Ausfall
- âŒ Keine Fallback-Logik

---

### Szenario 5: ML Chaos Injection

**Ziel:** PrÃ¼fen, ob ML-Anomalie-Erkennung nicht zu Overreaction fÃ¼hrt

**Setup:**
- Injiziere absichtlich anomale Transaktionen (z. B. 10Ã— Durchschnitt)
- Edge-of-Chaos Metriken tracken

**Erwartung:**
- âœ… Anomalien werden **markiert**, nicht blockiert
- âœ… CI-Score bleibt im Safe-Range (0.3â€“0.7)
- âœ… Keine Throttle-Spirale

**Failure-Symptome:**
- âŒ System blockiert bei jeder Anomalie
- âŒ CI-Score kippt in Extreme (< 0.1 oder > 0.9)

---

### Szenario 6: Crash / Replay

**Ziel:** PrÃ¼fen, ob Crash-Recovery via Replay deterministisch ist

**Setup:**
- 100 Events schreiben
- State in Projections merken (Snapshot)
- Projections lÃ¶schen (simulierter Crash)
- Replay ausfÃ¼hren

**Erwartung:**
- âœ… Nach Replay: identischer State
- âœ… Alle Invarianten erfÃ¼llt
- âœ… Keine Idempotency-Violations beim Replay

**Failure-Symptome:**
- âŒ State-Drift nach Replay
- âŒ Invarianten verletzt

---

## 5ï¸âƒ£ Hard Gates

### Gate A â€” Event Integrity

**PrÃ¼fung:**
```python
# Idempotency Key wirksam?
assert len(duplicate_events) == 0

# Schema-Version gesetzt?
for event in events:
    assert event.schema_version > 0

# Correlation/Causation IDs korrekt?
for event in events:
    assert event.correlation_id is not None
    if event.causation_id:
        assert causation_event_exists(event.causation_id)
```

**Go/No-Go:**
- âœ… GO: Alle Events valide, keine Duplikate
- âŒ NO-GO: Idempotency-Violations > 0

---

### Gate B â€” Projection Integrity

**PrÃ¼fung:**
```python
# Balance == Sum(Event-Deltas)?
for agent_id, balance in balances.items():
    deltas = sum_deltas_for_agent(agent_id)
    assert abs(balance - deltas) < 0.01  # Floating-Point-Toleranz

# Keine NaN / Inf?
for balance in balances.values():
    assert not math.isnan(balance)
    assert not math.isinf(balance)

# Kein Drift nach Replay?
original_state = snapshot_projections()
replay_all()
replayed_state = snapshot_projections()
assert original_state == replayed_state
```

**Go/No-Go:**
- âœ… GO: Balance-Invarianten erfÃ¼llt, Replay deterministisch
- âŒ NO-GO: Drift > 0

---

### Gate C â€” Human Gate Safety

**PrÃ¼fung:**
```python
# Approval serialisiert (OCC)?
approvals = get_approval_events()
assert len(approvals) <= 1  # Nur 1 Final Decision

# Audit-Log vollstÃ¤ndig?
for approval in approvals:
    assert audit_log_contains(approval.event_id)
```

**Go/No-Go:**
- âœ… GO: OCC wirksam, Audit vollstÃ¤ndig
- âŒ NO-GO: Race Conditions in Approvals

---

### Gate D â€” Failure Safety

**PrÃ¼fung:**
```python
# KARMA-Ausfall ohne Crash?
with simulate_karma_down():
    result = consume_credits(agent_id, 50)
    assert result.success  # Fallback greift

# ML-Anomalie markiert, nicht blockiert?
inject_anomaly(agent_id, amount=10000)
result = consume_credits(agent_id, 10000)
assert result.success
assert "anomaly_detected" in result.metadata
```

**Go/No-Go:**
- âœ… GO: Graceful Degradation funktioniert
- âŒ NO-GO: Crashes bei Service-Ausfall

---

### Gate E â€” Load Reality

**PrÃ¼fung:**
```python
# â‰¥ 30 Minuten Dauerlauf?
runtime = measure_test_duration()
assert runtime >= 1800  # 30 Minuten

# P95 Latenz < Grenzwert?
latencies = collect_latencies()
p95 = percentile(latencies, 95)
assert p95 < 500  # ms

# Memory-Leak-Trend?
memory_samples = collect_memory_usage()
trend = linear_regression_slope(memory_samples)
assert trend < 0.1  # MB/Minute
```

**Go/No-Go:**
- âœ… GO: System stabil Ã¼ber 30 Min, Latenz akzeptabel
- âŒ NO-GO: Memory-Leak oder Performance-Degradation

---

## 6ï¸âƒ£ AusfÃ¼hrung

### Manueller Start

```bash
# Im Projekt-Root
cd /home/user/BRAiN

# Test-Harness ausfÃ¼hren
docker compose exec backend python backend/tests/run_live_credit_tests.py

# Oder direkt mit pytest
docker compose exec backend pytest backend/tests/run_live_credit_tests.py -v
```

### Mit Parametern

```bash
# Concurrency Ã¼berschreiben
docker compose exec backend python backend/tests/run_live_credit_tests.py --concurrency 300

# Seed setzen
docker compose exec backend python backend/tests/run_live_credit_tests.py --seed 1337

# Alle Szenarien einzeln
docker compose exec backend python backend/tests/run_live_credit_tests.py --scenario credit_storm
docker compose exec backend python backend/tests/run_live_credit_tests.py --scenario approval_race
```

### VollstÃ¤ndiger Durchlauf

```bash
# Alle 6 Szenarien + 5 Gates
docker compose exec backend python backend/tests/run_live_credit_tests.py --full

# Mit JSON-Report
docker compose exec backend python backend/tests/run_live_credit_tests.py --full --report-json reports/live_test_report.json
```

---

## 7ï¸âƒ£ Erwartete Ergebnisse

### Szenario-Matrix (Target)

| Szenario | Status | Throughput | P95 Latency | Invarianten |
|----------|--------|------------|-------------|-------------|
| Credit Storm | âœ… PASS | > 100 req/s | < 300 ms | âœ… OK |
| Synergy Anti-Gaming | âœ… PASS | â€” | â€” | âœ… OK |
| Approval Race | âœ… PASS | â€” | < 100 ms | âœ… OK |
| KARMA Blackout | âœ… PASS | â€” | â€” | âœ… OK |
| ML Chaos | âœ… PASS | â€” | â€” | âœ… OK |
| Crash/Replay | âœ… PASS | â€” | â€” | âœ… OK |

### Gate-Matrix (Target)

| Gate | Kriterium | Target | Actual |
|------|-----------|--------|--------|
| A â€” Event Integrity | Idempotency Violations | 0 | â€” |
| B â€” Projection Integrity | Balance Drift | 0.0 | â€” |
| C â€” Human Gate Safety | Approval Races | 0 | â€” |
| D â€” Failure Safety | Crashes | 0 | â€” |
| E â€” Load Reality | Runtime | â‰¥ 30 Min | â€” |

---

## 8ï¸âƒ£ Failure Symptome

### Kritische Failures (NO-GO)

| Symptom | Gate | Root Cause | Fix Required |
|---------|------|------------|--------------|
| Negative Balance | B | Race Condition in consume() | âœ… Kritisch |
| Idempotency-Violations > 0 | A | Duplicate-Key-Check broken | âœ… Kritisch |
| Approval Race (>1 Final) | C | OCC not implemented | âœ… Kritisch |
| Crash bei KARMA-Ausfall | D | Missing Fallback | âœ… Kritisch |
| Memory Leak (Trend > 0.5 MB/min) | E | Projection Memory not GC'ed | âœ… Kritisch |

### Warnungen (CONDITIONAL)

| Symptom | Gate | Impact | Action |
|---------|------|--------|--------|
| P95 > 500 ms | E | Performance | âš ï¸ Optimieren |
| Anomaly Overreaction | D | UX | âš ï¸ Threshold tunen |
| Missing Audit Entries | C | Compliance | âš ï¸ Fix Logging |

---

## 9ï¸âƒ£ Cleanup & Wiederholung

### Event Journal lÃ¶schen

```bash
# Kompletter Reset
docker compose exec backend rm -f /app/storage/events/credits.jsonl

# Container neu starten
docker compose restart backend
```

### Projections neu aufbauen

```python
# Im Test-Harness
await replay_engine.replay_all()
```

### Report-Archivierung

```bash
# Timestamped Report
mv reports/live_test_report.json reports/live_test_report_$(date +%Y%m%d_%H%M%S).json

# Git committen
git add reports/live_test_report_*.json
git commit -m "test: Live Test Report $(date +%Y-%m-%d)"
```

---

## ğŸ¯ Erfolgs-Kriterien (Go/No-Go)

### âœ… GO â€” NÃ¤chste Phase (5a: Postgres Event Store)

**Bedingungen:**
- âœ… Alle 6 Szenarien: PASS
- âœ… Alle 5 Gates: PASS
- âœ… Keine kritischen Failures
- âœ… P95 < 500 ms
- âœ… 30-Min-Dauerlauf ohne Drift

**Empfehlung:**
> "System stabil. Event Sourcing Foundation production-ready. **Freigabe fÃ¼r Phase 5a (Postgres Event Store)**."

---

### âš ï¸ CONDITIONAL â€” Weiter testen

**Bedingungen:**
- âš ï¸ 1â€“2 Szenarien: FAIL (nicht-kritisch)
- âš ï¸ Gates A/B: PASS, aber C/D/E: Warnungen
- âš ï¸ P95 > 500 ms, aber < 1000 ms

**Empfehlung:**
> "System grundsÃ¤tzlich stabil, aber Performance/Governance-Optimierung nÃ¶tig. **Weiter testen fÃ¼r X Tage, dann Re-Evaluation**."

---

### âŒ NO-GO â€” Evolution blockiert

**Bedingungen:**
- âŒ â‰¥ 3 Szenarien: FAIL
- âŒ Gate A oder B: FAIL (Invarianten verletzt)
- âŒ Kritische Failures (Crash, Race, Negative Balance)

**Empfehlung:**
> "Kritische Risiken identifiziert. **Evolution blockiert bis Fixes implementiert**. Phase 5â€“8 weiterhin gesperrt."

---

## ğŸ“Š Report-Template

Siehe: `/home/user/BRAiN/backend/tests/LIVE_TEST_REPORT_TEMPLATE.md`

---

## ğŸ“ Ã„nderungshistorie

| Datum | Version | Autor | Ã„nderung |
|-------|---------|-------|----------|
| 2024-12-30 | 1.0 | Claude | Initial Playbook (Event Sourcing MVP) |

---

**Status:** âœ… Bereit fÃ¼r AusfÃ¼hrung
**NÃ¤chster Schritt:** Test Harness implementieren (`run_live_credit_tests.py`)
