# Sprint 2: Missions Architecture Decision

**Status:** âœ… **DECIDED - Migrate LEGACY Implementation**
**Date:** 2025-12-28
**Analyzed By:** Sprint 2 EventStream Migration Team

---

## Executive Summary

**Problem:** BRAiN has TWO missions implementations running simultaneously with conflicting architectures.

**Discovery:** The systems are **INCOMPATIBLE and BROKEN**:
- NEW API creates missions that are NEVER executed (orphaned)
- LEGACY worker runs but can't see NEW missions
- Route collision causes API requests to hit NEW (broken) instead of LEGACY (working)

**Decision:** **Migrate LEGACY implementation** - it's the only functional system.

---

## Architecture Analysis

### System 1: LEGACY (`backend/modules/missions/`)

**Location:** `backend/modules/missions/`

**Components:**
```
modules/missions/
â”œâ”€â”€ mission_control_runtime.py  # EventStream integration layer âœ…
â”œâ”€â”€ queue.py                    # Redis ZSET priority queue
â”œâ”€â”€ worker.py                   # Background worker (started in main.py)
â”œâ”€â”€ models.py                   # MissionPayload, MissionQueueEntry
â”œâ”€â”€ schemas.py                  # API response models
â””â”€â”€ api/routes/missions.py      # Full-featured API router
```

**Architecture:**
```
Client â†’ API Router â†’ Runtime â†’ Queue (Redis ZSET)
                              â†“
                         EventStream âœ…
                              â†“
                         Worker (background)
                              â†“
                         Mission Execution
```

**Features:**
- âœ… Redis ZSET-based priority queue
- âœ… Background worker processing
- âœ… EventStream integration (TASK_CREATED events)
- âœ… Event history API (`/events/history`)
- âœ… Event stats API (`/events/stats`)
- âœ… Queue preview API (`/queue`)
- âœ… Worker status API (`/worker/status`)
- âœ… Health checks
- âœ… Actually executes missions

**EventStream Coverage:**
- âœ… `TASK_CREATED` (line 92-100 in mission_control_runtime.py)
- â“ Missing: TASK_STARTED, TASK_COMPLETED, TASK_FAILED (execution lifecycle)

**Integration Points:**
- `backend/main.py:34` - Worker import
- `backend/main.py:135-136` - Worker startup in lifespan
- `backend/main.py:148-149` - Worker shutdown
- `backend/api/routes/missions.py` - Auto-discovered router

**Redis Keys:**
- Queue: Likely `brain:missions:queue` (ZSET)
- Events: EventStream manages (`brain:events:*`)

---

### System 2: NEW (`app/modules/missions/`)

**Location:** `app/modules/missions/`

**Components:**
```
app/modules/missions/
â”œâ”€â”€ service.py       # Direct Redis CRUD operations âŒ NO EventStream
â”œâ”€â”€ executor.py      # Mock executor (just sleeps) âŒ
â”œâ”€â”€ router.py        # Modern REST API with auth
â””â”€â”€ models.py        # Mission, MissionCreate, MissionStatus
```

**Architecture:**
```
Client â†’ API Router â†’ Service â†’ Redis (direct CRUD)
                              â†“
                         âŒ NO EventStream
                         âŒ NO Queue
                         âŒ NO Worker Integration
                              â†“
                         Mock Executor (asyncio.create_task)
                              â†“
                         âŒ ORPHANED - never actually runs
```

**Features:**
- âœ… Modern REST API design
- âœ… Security/auth integration (`get_current_principal`)
- âœ… Mission CRUD (create, get, list, update_status)
- âœ… Mission logging (`/log`)
- âœ… Statistics (`/stats/overview`)
- âŒ NO EventStream integration
- âŒ NO queue system
- âŒ NO background worker
- âŒ Mock executor (just sleeps)
- âŒ Missions created but NEVER executed

**Redis Keys:**
- Mission data: `brain:missions:mission:{id}` (String - JSON)
- Index: `brain:missions:index` (Set)
- Logs: `brain:missions:log:{id}` (List)
- Stats: `brain:missions:stats` (String - JSON)

**Integration Points:**
- `backend/main.py:66` - Router import
- `backend/main.py:245` - Router registration (**REGISTERED FIRST - WINS**)

---

## Critical Problem: Route Collision

**In `backend/main.py`:**

```python
# Line 245: NEW router registered FIRST
app.include_router(app_missions_router, tags=["missions"])

# Line 248: LEGACY router auto-discovered SECOND
_include_legacy_routers(app)  # Discovers backend/api/routes/missions.py
```

**FastAPI Behavior:** First registered router WINS on path collision.

**Result:**
- Client requests to `/api/missions/*` hit NEW router
- NEW router creates missions in `brain:missions:mission:{id}` keys
- LEGACY worker reads from MissionQueue (different keys)
- **Missions are created but NEVER executed** âŒ

---

## Storage Collision

**NEW Implementation:**
```python
# app/modules/missions/service.py
MISSION_KEY_PREFIX = "brain:missions:mission:"  # {id} â†’ JSON
MISSION_INDEX_KEY = "brain:missions:index"      # Set
MISSION_LOG_PREFIX = "brain:missions:log:"      # {id} â†’ List
MISSION_STATS_KEY = "brain:missions:stats"      # JSON
```

**LEGACY Implementation:**
```python
# backend/modules/missions/queue.py (inferred)
Queue key: likely "brain:missions:queue"  # ZSET with priority scores
```

**Problem:** Different key spaces â†’ **NO DATA SHARING** â†’ Systems don't see each other.

---

## Worker Analysis

**LEGACY Worker:**
```python
# backend/main.py:132-149
if os.getenv("ENABLE_MISSION_WORKER", "true").lower() == "true":
    mission_worker_task = await start_mission_worker()
    logger.info("âœ… Mission worker started")
```

**Status:** âœ… Running
**Processing:** MissionQueue (LEGACY keys)
**Problem:** Can't see NEW missions (different Redis keys)

**NEW "Executor":**
```python
# app/modules/missions/executor.py:10-34
class MissionExecutor:
    async def execute(self, mission: Mission) -> None:
        await asyncio.sleep(1.0)  # Mock work
        await update_status(mission.id, MissionStatus.COMPLETED)
```

**Status:** âŒ Mock implementation
**Trigger:** `asyncio.create_task()` in router (fire-and-forget)
**Problem:** No queue, no priority, no retry, just sleeps

---

## EventStream Coverage

### LEGACY Implementation

**File:** `backend/modules/missions/mission_control_runtime.py`

**Current Coverage:**
```python
# Lines 24-29: Imports
from backend.mission_control_core.core import (
    EventStream,
    Event,
    EventType,
    emit_task_event,
)

# Line 64: Initialization
self.event_stream = EventStream(redis_url=self.redis_url)
await self.event_stream.initialize()

# Lines 92-100: Event Publishing
await emit_task_event(
    self.event_stream,
    task_id=result.mission_id,
    event_type=EventType.TASK_CREATED,
    source=created_by,
    mission_id=result.mission_id,
    extra_data={
        "mission_type": payload.type,
        "priority": payload.priority.name,
    }
)
```

**Events Published:**
- âœ… `TASK_CREATED` - When mission enqueued

**Missing Events (Execution Lifecycle):**
- âŒ `TASK_STARTED` - When worker picks up mission
- âŒ `TASK_COMPLETED` - When mission succeeds
- âŒ `TASK_FAILED` - When mission fails
- âŒ `TASK_RETRIED` - When mission retries
- âŒ `TASK_CANCELLED` - When mission cancelled

**Estimated Missing:** 5 event types

### NEW Implementation

**EventStream Coverage:** âŒ **NONE** - No imports, no integration

---

## Decision Matrix

| Criteria | LEGACY | NEW | Merge Both |
|----------|--------|-----|------------|
| **Functional** | âœ… Yes | âŒ No (broken) | âš ï¸ After effort |
| **EventStream** | âœ… Partial (1 event) | âŒ None | âœ… After migration |
| **Queue System** | âœ… Redis ZSET | âŒ None | âœ… From LEGACY |
| **Worker** | âœ… Background worker | âŒ Mock executor | âœ… From LEGACY |
| **Modern REST** | âš ï¸ Basic | âœ… Full featured | âœ… From NEW |
| **Security/Auth** | âŒ None | âœ… get_current_principal | âœ… From NEW |
| **API Coverage** | âœ… Full (8 endpoints) | âš ï¸ Partial (7 endpoints) | âœ… Combined |
| **Migration Effort** | ğŸŸ¢ Low (4-6h) | ğŸ”´ High (12-16h) | ğŸ”´ Very High (20-30h) |
| **Risk** | ğŸŸ¢ Low (already works) | ğŸ”´ High (full rebuild) | ğŸ”´ Very High (complexity) |
| **Production Ready** | âœ… Yes (in use) | âŒ No (never worked) | âš ï¸ After testing |

---

## Options Analysis

### Option A: Migrate LEGACY âœ… **RECOMMENDED**

**Description:** Complete EventStream migration for LEGACY implementation.

**Tasks:**
1. Disable NEW router (comment out `main.py:245`)
2. Verify LEGACY router discovery
3. Add 5 missing event types (TASK_STARTED, COMPLETED, FAILED, RETRIED, CANCELLED)
4. Update worker to publish execution events
5. Write 15+ tests for all event types
6. Update documentation
7. Remove NEW implementation (cleanup)

**Effort:** 4-6 hours

**Pros:**
- âœ… Already functional (queue + worker)
- âœ… Partially migrated (TASK_CREATED exists)
- âœ… Low risk (extends working system)
- âœ… Fast delivery
- âœ… Production-ready (already in use)

**Cons:**
- âŒ No security/auth integration
- âŒ Less modern REST design
- âŒ Loses NEW's cleaner models

**Risk:** ğŸŸ¢ **LOW**

---

### Option B: Migrate NEW

**Description:** Add EventStream, queue, worker to NEW implementation.

**Tasks:**
1. Integrate EventStream into service.py
2. Build queue system (Redis ZSET)
3. Build background worker
4. Replace mock executor with real execution
5. Add 6+ event types
6. Write 18+ tests
7. Migrate data from LEGACY to NEW keys
8. Disable LEGACY worker

**Effort:** 12-16 hours

**Pros:**
- âœ… Modern REST design
- âœ… Security/auth integration
- âœ… Cleaner models

**Cons:**
- âŒ Full rebuild required
- âŒ NEW never worked (untested architecture)
- âŒ Data migration complexity
- âŒ High risk (greenfield)
- âŒ Longer delivery time

**Risk:** ğŸ”´ **HIGH**

---

### Option C: Merge Both

**Description:** Combine NEW API design with LEGACY backend.

**Tasks:**
1. Analyze incompatibilities
2. Design unified data model
3. Refactor NEW router to use LEGACY backend
4. Migrate LEGACY to use NEW models
5. Merge Redis key spaces
6. Migrate EventStream to unified system
7. Add security to LEGACY
8. Comprehensive testing
9. Data migration scripts

**Effort:** 20-30 hours

**Pros:**
- âœ… Best of both worlds
- âœ… Modern API + working backend
- âœ… Full feature set

**Cons:**
- âŒ Very high complexity
- âŒ Long delivery time
- âŒ High risk (merge conflicts)
- âŒ Extensive testing required

**Risk:** ğŸ”´ **VERY HIGH**

---

### Option D: Quick Fix (Bridge Solution)

**Description:** Make NEW router use LEGACY backend.

**Tasks:**
1. Modify NEW service.py to call LEGACY runtime
2. Keep NEW router for API surface
3. Redirect to LEGACY queue/worker
4. Add EventStream passthrough

**Effort:** 6-8 hours

**Pros:**
- âœ… Quick fix
- âœ… Preserves NEW API design
- âœ… Uses working LEGACY backend

**Cons:**
- âŒ Band-aid solution
- âŒ Technical debt
- âŒ Confusing architecture
- âŒ Still needs full migration later

**Risk:** ğŸŸ¡ **MEDIUM**

---

## Final Decision: **Option A - Migrate LEGACY** âœ…

### Rationale

1. **Functionality First**
   - LEGACY is the ONLY working implementation
   - NEW creates orphaned missions (user-facing bug)
   - Can't ship broken NEW in Sprint 2

2. **EventStream Readiness**
   - LEGACY already has EventStream (1/6 events)
   - Adding 5 events is straightforward
   - NEW requires ground-up integration

3. **Risk vs Reward**
   - LEGACY: Low risk, fast delivery (4-6h)
   - NEW: High risk, long delivery (12-16h), untested
   - Sprint 2 goal is EventStream migration, not architecture overhaul

4. **Production Impact**
   - LEGACY is likely already in production use
   - NEW has never worked (no user impact from removal)
   - Minimal disruption to existing workflows

5. **Sprint Velocity**
   - Sprint 2 has 3-4 more modules to migrate after missions
   - Can't spend 20-30h on merge experiment
   - Need fast, reliable delivery

### Trade-offs Accepted

- âŒ Won't get NEW's security/auth integration (defer to Sprint 3)
- âŒ Won't get NEW's cleaner REST design (acceptable)
- âŒ Technical debt remains (but working system > broken modern code)

### Future Work (Post-Sprint 2)

- **Sprint 3 or later:** Add security/auth to LEGACY
- **Sprint 4 or later:** Refactor LEGACY to modern REST patterns
- **Sprint 5 or later:** Remove NEW implementation entirely

---

## Implementation Plan

### Phase 1: Disable NEW Router (30 min)

**File:** `backend/main.py`

```python
# Line 245: Comment out NEW router
# app.include_router(app_missions_router, tags=["missions"])  # DISABLED: Route collision with LEGACY
```

**Verify:** `curl http://localhost:8000/api/missions/info` returns LEGACY response

---

### Phase 2: Analyze LEGACY EventStream (1h)

**Tasks:**
1. Read `backend/modules/missions/worker.py` - identify execution lifecycle
2. Read `backend/modules/missions/queue.py` - identify event trigger points
3. Map event types to execution states
4. Document current vs required events

**Deliverable:** Event coverage analysis document

---

### Phase 3: Add Missing Events (2-3h)

**Events to Add:**

1. **TASK_STARTED** (`EventType.TASK_STARTED`)
   - When: Worker picks mission from queue
   - Location: `worker.py` - start of execution
   - Payload: `{mission_id, type, priority, started_at, worker_id}`

2. **TASK_COMPLETED** (`EventType.TASK_COMPLETED`)
   - When: Mission execution succeeds
   - Location: `worker.py` - after successful execution
   - Payload: `{mission_id, duration_ms, result_summary, completed_at}`

3. **TASK_FAILED** (`EventType.TASK_FAILED`)
   - When: Mission execution fails
   - Location: `worker.py` - exception handler
   - Payload: `{mission_id, error, retry_count, failed_at, will_retry}`

4. **TASK_RETRIED** (`EventType.TASK_RETRIED`)
   - When: Mission re-enqueued after failure
   - Location: `worker.py` - retry logic
   - Payload: `{mission_id, retry_count, max_retries, next_attempt_at}`

5. **TASK_CANCELLED** (`EventType.TASK_CANCELLED`)
   - When: Mission cancelled via API
   - Location: `api/routes/missions.py` - cancel endpoint (if exists)
   - Payload: `{mission_id, cancelled_by, cancelled_at, reason}`

**Pattern:** Use existing `emit_task_event()` helper from `mission_control_runtime.py`

---

### Phase 4: Tests (1-2h)

**Test File:** `backend/tests/test_missions_events.py`

**Coverage:**
- âœ… TASK_CREATED event published on enqueue
- âœ… TASK_STARTED event published when worker picks mission
- âœ… TASK_COMPLETED event published on success
- âœ… TASK_FAILED event published on exception
- âœ… TASK_RETRIED event published on retry
- âœ… TASK_CANCELLED event published on cancel (if endpoint exists)
- âœ… Event envelope structure (Charter v1.0)
- âœ… Non-blocking event publishing
- âœ… Graceful degradation without EventStream

**Estimated Tests:** 15-18 tests

---

### Phase 5: Documentation (1h)

**Files to Update:**

1. **`backend/modules/missions/README.md`** (create)
   - Overview
   - Architecture diagram
   - EventStream integration
   - Event types (6 total)
   - Usage examples
   - Consumer guidelines

2. **`backend/modules/missions/EVENTS.md`** (create)
   - Complete event specifications
   - Payload schemas
   - Consumer recommendations

3. **`SPRINT2_MISSIONS_MIGRATION.md`** (create)
   - Migration report
   - Changes made
   - Testing results
   - Metrics

---

## Timeline Estimate

| Phase | Duration | Dependencies |
|-------|----------|--------------|
| Phase 1: Disable NEW | 30 min | None |
| Phase 2: Analysis | 1h | Phase 1 |
| Phase 3: Add Events | 2-3h | Phase 2 |
| Phase 4: Tests | 1-2h | Phase 3 |
| Phase 5: Documentation | 1h | Phase 4 |
| **Total** | **5-7h** | Sequential |

**Buffer:** +1h for unexpected issues
**Final Estimate:** **6-8 hours**

---

## Success Criteria

### Must Have (Sprint 2)
- âœ… NEW router disabled (no route collision)
- âœ… LEGACY router serving all requests
- âœ… 6 event types published (CREATED, STARTED, COMPLETED, FAILED, RETRIED, CANCELLED)
- âœ… 15+ tests passing
- âœ… Charter v1.0 compliance
- âœ… Non-blocking event publishing
- âœ… Documentation complete

### Nice to Have (Future)
- âšª Security/auth integration (defer to Sprint 3)
- âšª Modern REST refactoring (defer to Sprint 4)
- âšª NEW implementation removal (defer to Sprint 5)

---

## Appendix: Key Files

### LEGACY Implementation
```
backend/modules/missions/
â”œâ”€â”€ mission_control_runtime.py   # EventStream integration âœ…
â”œâ”€â”€ queue.py                     # Redis ZSET queue
â”œâ”€â”€ worker.py                    # Background worker âš ï¸ NEEDS EVENTS
â”œâ”€â”€ models.py                    # Data models
â”œâ”€â”€ schemas.py                   # API schemas
â””â”€â”€ (to create)
    â”œâ”€â”€ README.md               # Documentation
    â””â”€â”€ EVENTS.md               # Event specifications

backend/api/routes/
â””â”€â”€ missions.py                 # API router (auto-discovered)

backend/tests/
â””â”€â”€ test_missions_events.py     # EventStream tests (to create)
```

### NEW Implementation (TO BE DISABLED)
```
app/modules/missions/
â”œâ”€â”€ service.py      # âŒ Direct Redis, no EventStream
â”œâ”€â”€ executor.py     # âŒ Mock executor
â”œâ”€â”€ router.py       # âŒ Broken (creates orphaned missions)
â””â”€â”€ models.py       # Modern models (could salvage later)
```

### Integration Points
```
backend/main.py
â”œâ”€â”€ Line 34:  Worker import
â”œâ”€â”€ Line 66:  NEW router import (DISABLE)
â”œâ”€â”€ Line 135: Worker startup
â”œâ”€â”€ Line 148: Worker shutdown
â”œâ”€â”€ Line 245: NEW router registration (COMMENT OUT) âŒ
â””â”€â”€ Line 248: LEGACY router auto-discovery âœ…
```

---

## Risks & Mitigation

### Risk 1: LEGACY might have undocumented dependencies
**Likelihood:** Medium
**Impact:** Medium
**Mitigation:** Thorough testing before disabling NEW

### Risk 2: Existing users might rely on NEW API endpoints
**Likelihood:** Low (NEW never worked)
**Impact:** Low
**Mitigation:** Check logs for NEW endpoint usage before disabling

### Risk 3: EventStream changes might break existing TASK_CREATED consumers
**Likelihood:** Low
**Impact:** Medium
**Mitigation:** Maintain backward compatibility, add new events incrementally

---

## Approval

**Recommended By:** Sprint 2 Migration Team
**Reviewed By:** [Pending]
**Approved By:** [Pending]
**Date:** 2025-12-28

---

**Next Steps:** Proceed to Phase 1 - Disable NEW Router
