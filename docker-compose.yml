services:
  backend:
    build:
      context: ./backend
    container_name: brain-backend
    env_file:
      - .env
    # ports:
    #   - "8000:8000"  # Defined in environment-specific overrides
    depends_on:
      - postgres
      - redis
    restart: unless-stopped
    networks:
      - brain_internal

  control_deck:
    build:
      context: ./frontend/control_deck
    container_name: brain-control-deck
    environment:
      - NEXT_PUBLIC_BRAIN_API_BASE=http://backend:8000
    # ports:
    #   - "3000:3000"  # Defined in environment-specific overrides
    depends_on:
      - backend
    restart: unless-stopped
    networks:
      - brain_internal

  axe_ui:
    build:
      context: ./frontend/axe_ui
    container_name: brain-axe-ui
    environment:
      - NEXT_PUBLIC_BRAIN_API_BASE=http://backend:8000
    # ports:
    #   - "3001:3000"  # Defined in environment-specific overrides
    depends_on:
      - backend
    restart: unless-stopped
    networks:
      - brain_internal

  postgres:
    image: postgres:16
    container_name: brain-postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-brain}
      POSTGRES_USER: ${POSTGRES_USER:-brain}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-brain}
    volumes:
      - brain_pg_data:/var/lib/postgresql/data
    # ports:
    #   - "5432:5432"  # Removed for Coolify - internal access only
    restart: unless-stopped
    networks:
      - brain_internal

  redis:
    image: redis:7-alpine
    container_name: brain-redis
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5
    # ports:
    #   - "6379:6379"  # Removed for Coolify - internal access only
    restart: unless-stopped
    networks:
      - brain_internal

  qdrant:
    image: qdrant/qdrant:latest
    container_name: brain-qdrant
    volumes:
      - brain_qdrant_data:/qdrant/storage
    # ports:
    #   - "6333:6333"  # Removed for Coolify - internal access only
    restart: unless-stopped
    networks:
      - brain_internal

  ollama:
    image: ollama/ollama:latest
    container_name: brain-ollama
    volumes:
      - brain_ollama_data:/root/.ollama
    # ports:
    #   - "11434:11434"  # Removed for Coolify - internal access only
    restart: unless-stopped
    networks:
      - brain_internal

  # OpenWebUI temporarily disabled for initial deployment
  # Uncomment when ready to deploy chat interface
  # openwebui:
  #   image: ghcr.io/open-webui/open-webui:main
  #   container_name: brain-openwebui
  #   volumes:
  #     - brain_openwebui_data:/app/backend/data
  #   environment:
  #     - OLLAMA_BASE_URL=http://ollama:11434
  #     - DATABASE_URL=sqlite:////app/backend/data/webui.db
  #   depends_on:
  #     - ollama
  #   restart: unless-stopped
  #   networks:
  #     - brain_internal

networks:
  brain_internal:
    driver: bridge
    # Let Docker automatically assign a free subnet to avoid conflicts
    # Coolify may already use 172.20.0.0/16 or other predefined subnets

volumes:
  brain_pg_data:
  brain_qdrant_data:
  brain_ollama_data:
  brain_openwebui_data:
